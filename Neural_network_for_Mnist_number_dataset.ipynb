
Open In Colab
Table of Contents
1  Loading the MNIST dataset in Keras
2  The network architecture
3  The compilation step
4  Preparing the image data
5  Preparing the labels
6  Training and Testing
Loading the MNIST dataset in Keras
from keras.datasets import mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
The images are encoded as Numpy arrays, and the labels are an array of digits, ranging from 0 to 9.
train_images.shape
(60000, 28, 28)
len(train_labels)
60000
train_labels
array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)
test_images.shape
(10000, 28, 28)
len(test_labels)
10000
test_labels
array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)
Let's build the network

The network architecture
The core building block of neural networks is the layer, a data-processing module that you can think of as a filter for data.

Some data goes in, and it comes out in a more useful form.
Layers extract representations (hopefully, meaningful for the data problem at hand) out of the data fed into them.
Most of deep learning consists of chaining together simple layers that will implement a form of progressive data distillation.

A deep learning model is like a sieve for data-processing, made of a succession of increasingly refined data filters--the layers.
from keras import models
from keras import layers
network = models.Sequential()
# Dense(512) is a fully-connected layer with 512 hidden units.
# in the first layer, you must specify the expected input data shape :
# here, 28 X 28=784 -dimensional vectors.
network.add(layers.Dense(32, activation='relu', input_shape=(28 * 28, )))
network.add(layers.Dense(16, activation='tanh'))
network.add(layers.Dense(8, activation='relu'))
network.add(layers.Dense(10, activation='softmax'))
Our network consists of a sequence of two Dense layers, which are densely connected (also called fully connected) neural layers.
The second (and last) layer is a 10-way softmax layer, which means it will return an array of 10 probability scores. Each score will be the probability that the current digit image belongs to one of our 10 digit classes.
The compilation step
To make the network ready for training, we need to pick three more things, as part of the compilation step:
A loss function-- How the network will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.
An optimizer--The mechanism through which the network will update itself based on the data it sees and its loss function.
Metrics to monitor during training and testing--Here, we will only care about accuracy (the fraction of the images that were correctly classified).
network.compile(optimizer='adam',
                loss='categorical_crossentropy',
                metrics=['accuracy'])
    
Preparing the image data
Before training, we will preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the  interval.

train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255.
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255.
Preparing the labels
We also need to categorically encode the labels.

from tensorflow.keras.utils import to_categorical
train_labels = to_categorical(train_labels)
train_labels
array([[0., 0., 0., ..., 0., 0., 0.],
       [1., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)
test_labels = to_categorical(test_labels)
test_labels
array([[0., 0., 0., ..., 1., 0., 0.],
       [0., 0., 1., ..., 0., 0., 0.],
       [0., 1., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
Training and Testing
We are now ready to train the network, which in Keras is done via a call to the network's fit method--we fit the model to its training data:

network.fit(train_images, train_labels, epochs=20, batch_size=32)
Epoch 1/20
1875/1875 [==============================] - 7s 4ms/step - loss: 1.0201 - accuracy: 0.7934
Epoch 2/20
1875/1875 [==============================] - 6s 3ms/step - loss: 0.3276 - accuracy: 0.9412
Epoch 3/20
1875/1875 [==============================] - 7s 3ms/step - loss: 0.2021 - accuracy: 0.9538
Epoch 4/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.1554 - accuracy: 0.9620
Epoch 5/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.1314 - accuracy: 0.9664
Epoch 6/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.1157 - accuracy: 0.9692
Epoch 7/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.1049 - accuracy: 0.9721
Epoch 8/20
1875/1875 [==============================] - 7s 3ms/step - loss: 0.0959 - accuracy: 0.9745
Epoch 9/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0893 - accuracy: 0.9754
Epoch 10/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0818 - accuracy: 0.9775
Epoch 11/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0751 - accuracy: 0.9798
Epoch 12/20
1875/1875 [==============================] - 7s 3ms/step - loss: 0.0713 - accuracy: 0.9805
Epoch 13/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0676 - accuracy: 0.9820
Epoch 14/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0636 - accuracy: 0.9826
Epoch 15/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0619 - accuracy: 0.9827
Epoch 16/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0592 - accuracy: 0.9831
Epoch 17/20
1875/1875 [==============================] - 7s 3ms/step - loss: 0.0559 - accuracy: 0.9845
Epoch 18/20
1875/1875 [==============================] - 6s 3ms/step - loss: 0.0541 - accuracy: 0.9848
Epoch 19/20
1875/1875 [==============================] - 6s 3ms/step - loss: 0.0525 - accuracy: 0.9857
Epoch 20/20
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0514 - accuracy: 0.9852
<keras.callbacks.History at 0x7feb33204310>
Two quantities are displayed during training:

The loss of the network over the training data
The accuracy of the network over the training data
We quickly reach an accuracy of  on the training data.

Now let's check that the model performs well on the test set, too:
test_loss, test_acc = network.evaluate(test_images, test_labels)
313/313 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9648
print('Test Accuracy: {:.5f} '.format(test_acc))
Test Accuracy: 0.96480 
test_acc
0.9648000001907349
The test-set accuracy turns out to be --that is quite a bit lower than the training set accuracy. This gap between training and test accuracy is an example of overfitting:the fact that the ML models tend to perform worse on new data than on their training data.
from tensorflow.keras.utils import plot_model
plot_model(network, to_file='model.png')

import matplotlib.pyplot as plt
history =network.fit(train_images, train_labels, validation_split=0.33,epochs=20, batch_size=64)
history_dict = history.history
print(history_dict.keys())
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
Epoch 1/20
629/629 [==============================] - 5s 7ms/step - loss: 0.0360 - accuracy: 0.9907 - val_loss: 0.0373 - val_accuracy: 0.9909
Epoch 2/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0318 - accuracy: 0.9924 - val_loss: 0.0430 - val_accuracy: 0.9888
Epoch 3/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.0423 - val_accuracy: 0.9892
Epoch 4/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.0481 - val_accuracy: 0.9879
Epoch 5/20
629/629 [==============================] - 5s 8ms/step - loss: 0.0293 - accuracy: 0.9932 - val_loss: 0.0579 - val_accuracy: 0.9836
Epoch 6/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0303 - accuracy: 0.9919 - val_loss: 0.0541 - val_accuracy: 0.9846
Epoch 7/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0257 - accuracy: 0.9942 - val_loss: 0.0510 - val_accuracy: 0.9853
Epoch 8/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 0.0575 - val_accuracy: 0.9837
Epoch 9/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 0.0622 - val_accuracy: 0.9827
Epoch 10/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 0.0590 - val_accuracy: 0.9832
Epoch 11/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 0.0720 - val_accuracy: 0.9798
Epoch 12/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0225 - accuracy: 0.9949 - val_loss: 0.0752 - val_accuracy: 0.9790
Epoch 13/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.0740 - val_accuracy: 0.9790
Epoch 14/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0796 - val_accuracy: 0.9779
Epoch 15/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.0755 - val_accuracy: 0.9778
Epoch 16/20
629/629 [==============================] - 4s 6ms/step - loss: 0.0183 - accuracy: 0.9958 - val_loss: 0.0794 - val_accuracy: 0.9776
Epoch 17/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.0800 - val_accuracy: 0.9777
Epoch 18/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.0916 - val_accuracy: 0.9753
Epoch 19/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0175 - accuracy: 0.9955 - val_loss: 0.0829 - val_accuracy: 0.9779
Epoch 20/20
629/629 [==============================] - 4s 7ms/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: 0.0859 - val_accuracy: 0.9777
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])

